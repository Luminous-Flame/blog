 
블록으로 데이터 관리
큰 데이터 셋 128MB 등

네임노드가 전부 메모리에 블록 데이터 가지고있음
메타데이터 오버헤드를 줄이기 위해 파일 사이즈를 크게 키워서 운영

네임노드 복구 안정성을 위해 
백업을 따로 분리하여 관리 할것

/data/hadoopcluster 밑에 상태 체크

네임노드는 실시간이 아니라 5분정도 배치 잡 처럼 갱신
safe 모드

블록 카운트를 줄이면 failover가 빨라진다

50070 네임 노드의 UI 상태
8088 각 노드별로 어떤 작업이 돌고있는지 하둡 클러스터 메인 리소스 매니저 Yarn UI라고 보면 됨

SPARK (rolex)
인메모리 엔진

edge의 이유 
작업 하나당 드라이버 하나 (작업 진입점) 각각 하둡 데이터 워커 노드들에 작업을 뿌려주는 역할

5만개까지

--------------------------------------------------------------------

네임노드 UI 볼륨 failer 에서 확인가능 *노드 확인 가능*

하둡 계정으로 전환
jps

데몬을 내려도 네임노드는 내려갔다고 판단 x
10분 뒤에 내려갔다고 판단 o

레플리카 3 되어있어서 요청은 제대로 수행 됨
3개중 2개는 살아있어야 함

hdfs  --daemon stop datanode

/data12/datanode 에 데이터 적재 lock 이 되어있는데 데몬 내리면 좀 있다가 풀림 (10분)

--------------------------------------------------------------------

dead (데몬 다운)
decomission (노드 제외)
maintence (유지보수)

--------------------------------------------------------------------

tollerated 설정
클러스터 성향에 따라 설정
롤렉스에 설정 되어있음
갯수 만큼 버틴다 
디스크 교체 하려면
데몬 일일히 죽여야 함

--------------------------------------------------------------------

실시간 newhourly 원천 데이터 : 샤넬 
dsp 배치가 발생시키는 키워드 팩 같은 오래 보관해야 하는 데이터들 (ade 아카이빙) : 롤렉스
hdfs 로 로그워커 데이터 보냄

--------------------------------------------------------------------

ansible 커맨드 가이드
네임노드 백업 본 /data 밖에 두어야 함
 